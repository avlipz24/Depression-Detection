{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r5QavNuih3oy"
   },
   "outputs": [],
   "source": [
    "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
    "# THEN FEEL FREE TO DELETE THIS CELL.\n",
    "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
    "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
    "# NOTEBOOK.\n",
    "import kagglehub\n",
    "infamouscoder_mental_health_social_media_path = kagglehub.dataset_download('infamouscoder/mental-health-social-media')\n",
    "\n",
    "print('Data source import complete.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Adzd2-Cwh3o4"
   },
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:30:46.691293Z",
     "iopub.status.busy": "2023-06-22T10:30:46.690892Z",
     "iopub.status.idle": "2023-06-22T10:30:46.696788Z",
     "shell.execute_reply": "2023-06-22T10:30:46.695825Z",
     "shell.execute_reply.started": "2023-06-22T10:30:46.691261Z"
    },
    "id": "FJzD5HZNh3o6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q5Ga-M0Mh3o6"
   },
   "source": [
    "Get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:30:46.699002Z",
     "iopub.status.busy": "2023-06-22T10:30:46.698397Z",
     "iopub.status.idle": "2023-06-22T10:30:46.810084Z",
     "shell.execute_reply": "2023-06-22T10:30:46.809107Z",
     "shell.execute_reply.started": "2023-06-22T10:30:46.69897Z"
    },
    "id": "HXdJ-l26h3o7"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/mental-health-social-media/Mental-Health-Twitter.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:30:46.812176Z",
     "iopub.status.busy": "2023-06-22T10:30:46.811718Z",
     "iopub.status.idle": "2023-06-22T10:30:46.833594Z",
     "shell.execute_reply": "2023-06-22T10:30:46.832621Z",
     "shell.execute_reply.started": "2023-06-22T10:30:46.812138Z"
    },
    "id": "y_WFPVLvh3o8"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:30:46.835411Z",
     "iopub.status.busy": "2023-06-22T10:30:46.835055Z",
     "iopub.status.idle": "2023-06-22T10:30:46.850432Z",
     "shell.execute_reply": "2023-06-22T10:30:46.849484Z",
     "shell.execute_reply.started": "2023-06-22T10:30:46.835383Z"
    },
    "id": "ja5T3aIsh3o8"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8kLYn-kh3o9"
   },
   "source": [
    "Clearly there are no missing values in the dataset. But in case if missing values occur we can use certain methods like:\n",
    "- deleting the rows with missing values\n",
    "- deleting the column with too many missing values\n",
    "- filling the missing values with mean, median or mode of the column\n",
    "- using machine learning algorithms to predict the missing values for ex using regression to predict the missing values of a column.\n",
    "- using clustering algorithms to group the data points with missing values and then using the mean of the cluster to fill the missing values.\n",
    "- flag the missing values as a separate category.\n",
    "\n",
    " Now let's drop irrelevant columns from the dataset. The 'Unnamed: 0' here is the extra column which is not required for our analysis. So we will drop it. Also the 'id' column is not required for our analysis as it is just a unique identifier for each row. So we will drop it too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:30:46.853812Z",
     "iopub.status.busy": "2023-06-22T10:30:46.852847Z",
     "iopub.status.idle": "2023-06-22T10:30:46.870263Z",
     "shell.execute_reply": "2023-06-22T10:30:46.869045Z",
     "shell.execute_reply.started": "2023-06-22T10:30:46.85378Z"
    },
    "id": "v8NSAj2Lh3o9"
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 0', 'post_id', 'user_id'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSFoBan3h3o-"
   },
   "source": [
    "Convert the time to post creation to datetime format and use seperate columns for year, month and day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:30:46.872375Z",
     "iopub.status.busy": "2023-06-22T10:30:46.872017Z",
     "iopub.status.idle": "2023-06-22T10:30:52.949336Z",
     "shell.execute_reply": "2023-06-22T10:30:52.94828Z",
     "shell.execute_reply.started": "2023-06-22T10:30:46.872344Z"
    },
    "id": "dmxKYCExh3o-"
   },
   "outputs": [],
   "source": [
    "df.post_created=df.post_created.apply(pd.to_datetime)\n",
    "\n",
    "df[\"month\"]=df.post_created.dt.month\n",
    "df[\"year\"]=df.post_created.dt.year\n",
    "df[\"day\"]=df.post_created.dt.day\n",
    "\n",
    "df.drop(\"post_created\", axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dUjNai8hh3o_"
   },
   "source": [
    "Find the pearson correlation coefficient between the variables.\n",
    "\n",
    "- For r = 1, there is a perfect positive correlation between the variables.\n",
    "- For 0 < r < 1 there is a positive correlation between the variables.\n",
    "- For r = 0, there is no correlation between the variables.\n",
    "- For -1 < r < 0 there is a negative correlation between the variables.\n",
    "- For r = -1, there is a perfect negative correlation between the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:30:52.951186Z",
     "iopub.status.busy": "2023-06-22T10:30:52.950876Z",
     "iopub.status.idle": "2023-06-22T10:30:52.977103Z",
     "shell.execute_reply": "2023-06-22T10:30:52.976021Z",
     "shell.execute_reply.started": "2023-06-22T10:30:52.951161Z"
    },
    "id": "fPSlRlTkh3o_"
   },
   "outputs": [],
   "source": [
    "corr_matrix = df.corr()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:30:52.978658Z",
     "iopub.status.busy": "2023-06-22T10:30:52.978367Z",
     "iopub.status.idle": "2023-06-22T10:30:53.487795Z",
     "shell.execute_reply": "2023-06-22T10:30:53.486765Z",
     "shell.execute_reply.started": "2023-06-22T10:30:52.978634Z"
    },
    "id": "V_RM1HYeh3o_"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:30:53.490217Z",
     "iopub.status.busy": "2023-06-22T10:30:53.489151Z",
     "iopub.status.idle": "2023-06-22T10:30:53.495943Z",
     "shell.execute_reply": "2023-06-22T10:30:53.495072Z",
     "shell.execute_reply.started": "2023-06-22T10:30:53.490182Z"
    },
    "id": "3PaqfBIkh3o_"
   },
   "outputs": [],
   "source": [
    "def correlation(dataset, threshold):\n",
    "    col_corr = set() # Set of all the names of correlated columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i,j]) > threshold: # we are interested in absolute coeff value\n",
    "                colname = corr_matrix.columns[i] # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    return col_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:30:53.497634Z",
     "iopub.status.busy": "2023-06-22T10:30:53.49734Z",
     "iopub.status.idle": "2023-06-22T10:30:53.519809Z",
     "shell.execute_reply": "2023-06-22T10:30:53.518708Z",
     "shell.execute_reply.started": "2023-06-22T10:30:53.497603Z"
    },
    "id": "UNLzgu2Yh3pA"
   },
   "outputs": [],
   "source": [
    "corr_features = correlation(df, 0.85)\n",
    "corr_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:30:53.52142Z",
     "iopub.status.busy": "2023-06-22T10:30:53.521028Z",
     "iopub.status.idle": "2023-06-22T10:30:53.541968Z",
     "shell.execute_reply": "2023-06-22T10:30:53.540925Z",
     "shell.execute_reply.started": "2023-06-22T10:30:53.521393Z"
    },
    "id": "GIcB23HGh3pA"
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=corr_features)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UgdtUIlZh3pA"
   },
   "source": [
    "Since Friends and Followers are highly correlated, we have dropped the Friends column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:30:53.543548Z",
     "iopub.status.busy": "2023-06-22T10:30:53.54321Z",
     "iopub.status.idle": "2023-06-22T10:30:53.584549Z",
     "shell.execute_reply": "2023-06-22T10:30:53.583497Z",
     "shell.execute_reply.started": "2023-06-22T10:30:53.54352Z"
    },
    "id": "XKyb0A0gh3pA"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBNDqSDOh3pA"
   },
   "source": [
    "PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:30:53.586317Z",
     "iopub.status.busy": "2023-06-22T10:30:53.585937Z",
     "iopub.status.idle": "2023-06-22T10:30:53.780179Z",
     "shell.execute_reply": "2023-06-22T10:30:53.778993Z",
     "shell.execute_reply.started": "2023-06-22T10:30:53.586292Z"
    },
    "id": "EU478Xq6h3pA"
   },
   "outputs": [],
   "source": [
    "#Convert to lower case\n",
    "df[\"post_text\"] = df[\"post_text\"].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "\n",
    "#remove punctuation\n",
    "df[\"post_text\"] = df[\"post_text\"].str.replace('[^\\w\\s]','')\n",
    "\n",
    "#remove numbers\n",
    "df[\"post_text\"] = df[\"post_text\"].str.replace('\\d','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:30:53.786038Z",
     "iopub.status.busy": "2023-06-22T10:30:53.785648Z",
     "iopub.status.idle": "2023-06-22T10:30:54.310822Z",
     "shell.execute_reply": "2023-06-22T10:30:54.309887Z",
     "shell.execute_reply.started": "2023-06-22T10:30:53.786008Z"
    },
    "id": "OD8l7GKVh3pA"
   },
   "outputs": [],
   "source": [
    "#remove stopwords\n",
    "#nltk.download('stopwords')\n",
    "sw = stopwords.words(\"english\")\n",
    "df[\"post_text\"] = df[\"post_text\"].apply(lambda x: \" \".join(x for x in x.split() if x not in sw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:30:54.312456Z",
     "iopub.status.busy": "2023-06-22T10:30:54.31213Z",
     "iopub.status.idle": "2023-06-22T10:30:58.263167Z",
     "shell.execute_reply": "2023-06-22T10:30:58.262314Z",
     "shell.execute_reply.started": "2023-06-22T10:30:54.312429Z"
    },
    "id": "z8-pAhJjh3pB"
   },
   "outputs": [],
   "source": [
    "#Stemming\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_text(text):\n",
    "    stemmed_text = \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "    return stemmed_text\n",
    "\n",
    "df['post_text'] = df['post_text'].apply(stem_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:30:58.264948Z",
     "iopub.status.busy": "2023-06-22T10:30:58.264468Z",
     "iopub.status.idle": "2023-06-22T10:31:02.033581Z",
     "shell.execute_reply": "2023-06-22T10:31:02.032518Z",
     "shell.execute_reply.started": "2023-06-22T10:30:58.264918Z"
    },
    "id": "JOU855Boh3pB"
   },
   "outputs": [],
   "source": [
    "#tokenization\n",
    "from textblob import TextBlob\n",
    "#nltk.download(\"punkt\")\n",
    "df[\"tokens\"] = df[\"post_text\"].apply(lambda x: TextBlob(x).words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:31:02.035349Z",
     "iopub.status.busy": "2023-06-22T10:31:02.034922Z",
     "iopub.status.idle": "2023-06-22T10:31:02.346066Z",
     "shell.execute_reply": "2023-06-22T10:31:02.345086Z",
     "shell.execute_reply.started": "2023-06-22T10:31:02.035312Z"
    },
    "id": "fnYw4f3-h3pB"
   },
   "outputs": [],
   "source": [
    "#TF-IDF\n",
    "vectorizer_tf = TfidfVectorizer(stop_words=\"english\", max_features=1000)\n",
    "X_tf = vectorizer_tf.fit_transform(df[\"post_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:31:02.348036Z",
     "iopub.status.busy": "2023-06-22T10:31:02.347552Z",
     "iopub.status.idle": "2023-06-22T10:31:02.384651Z",
     "shell.execute_reply": "2023-06-22T10:31:02.383499Z",
     "shell.execute_reply.started": "2023-06-22T10:31:02.347996Z"
    },
    "id": "IVKoMTBTh3pB"
   },
   "outputs": [],
   "source": [
    "vectorizer_tf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:31:02.386483Z",
     "iopub.status.busy": "2023-06-22T10:31:02.386173Z",
     "iopub.status.idle": "2023-06-22T10:31:02.544282Z",
     "shell.execute_reply": "2023-06-22T10:31:02.543133Z",
     "shell.execute_reply.started": "2023-06-22T10:31:02.386457Z"
    },
    "id": "15KPCJdbh3pB"
   },
   "outputs": [],
   "source": [
    "#idf of each word\n",
    "all_feature_names = vectorizer_tf.get_feature_names_out()\n",
    "\n",
    "for word in all_feature_names:\n",
    "\n",
    "    #let's get the index in the vocabulary\n",
    "    indx = vectorizer_tf.vocabulary_.get(word)\n",
    "\n",
    "    #get the score\n",
    "    idf_score = vectorizer_tf.idf_[indx]\n",
    "\n",
    "    print(f\"{word} : {idf_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:31:02.546508Z",
     "iopub.status.busy": "2023-06-22T10:31:02.546049Z",
     "iopub.status.idle": "2023-06-22T10:31:02.726002Z",
     "shell.execute_reply": "2023-06-22T10:31:02.724784Z",
     "shell.execute_reply.started": "2023-06-22T10:31:02.546465Z"
    },
    "id": "Iv8f0S68h3pB"
   },
   "outputs": [],
   "source": [
    "#output of tf-idf\n",
    "X_tf.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hyNM_aJdh3pB"
   },
   "source": [
    "Cosine Similarity measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:31:02.72772Z",
     "iopub.status.busy": "2023-06-22T10:31:02.727294Z",
     "iopub.status.idle": "2023-06-22T10:31:02.733156Z",
     "shell.execute_reply": "2023-06-22T10:31:02.732049Z",
     "shell.execute_reply.started": "2023-06-22T10:31:02.727664Z"
    },
    "id": "JBF7DVPCh3pB"
   },
   "outputs": [],
   "source": [
    "#from sklearn.metrics.pairwise import cosine_similarity\n",
    "#\n",
    "#cos_sim = cosine_similarity(X_tf[:1000])\n",
    "#\n",
    "#df1 = df[:1000]\n",
    "#for i in range(len(df1['post_text'])):\n",
    "#    for j in range(len(df1['post_text'])):\n",
    "#        print(f\"Cosine similarity between document {i+1} and document {j+1}: {cos_sim[i][j]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Nw8r5nIh3pB"
   },
   "source": [
    "Implementing Similarity Measure for Text Processing(SMTP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:31:02.735038Z",
     "iopub.status.busy": "2023-06-22T10:31:02.734565Z",
     "iopub.status.idle": "2023-06-22T10:31:05.307889Z",
     "shell.execute_reply": "2023-06-22T10:31:05.306802Z",
     "shell.execute_reply.started": "2023-06-22T10:31:02.734999Z"
    },
    "id": "a6LGdLQbh3pC"
   },
   "outputs": [],
   "source": [
    "#getting the unique features in the document(tweet)and creating another column\n",
    "\n",
    "def get_unique_words(tweet):\n",
    "    words = tweet.split()\n",
    "    unique_words = list(set(words))\n",
    "    return unique_words\n",
    "\n",
    "df1 = df[:1000]\n",
    "for i in range(1000):\n",
    "    df1['unique_words'] = df1['post_text'].apply(lambda x: get_unique_words(x))\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:31:05.309655Z",
     "iopub.status.busy": "2023-06-22T10:31:05.30922Z",
     "iopub.status.idle": "2023-06-22T10:31:05.331811Z",
     "shell.execute_reply": "2023-06-22T10:31:05.330538Z",
     "shell.execute_reply.started": "2023-06-22T10:31:05.309623Z"
    },
    "id": "1Xf3oXvAh3pC"
   },
   "outputs": [],
   "source": [
    "def get_features(lists):\n",
    "    features = [word for sublist in lists for word in sublist if len(word) > 3]\n",
    "    return features\n",
    "\n",
    "df2 = df[:500]\n",
    "df3 = df[19500:]\n",
    "\n",
    "print(df2.head())\n",
    "\n",
    "df4 = pd.concat([df2, df3], axis=0)\n",
    "print(df4.head())\n",
    "\n",
    "req_lst = df4['tokens'].tolist()\n",
    "req_lst[:5]\n",
    "#selected_features = get_features(req_lst)\n",
    "#print(len(selected_features))\n",
    "#selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:31:05.333615Z",
     "iopub.status.busy": "2023-06-22T10:31:05.333013Z",
     "iopub.status.idle": "2023-06-22T10:31:05.342181Z",
     "shell.execute_reply": "2023-06-22T10:31:05.341108Z",
     "shell.execute_reply.started": "2023-06-22T10:31:05.333586Z"
    },
    "id": "97SCoUFfh3pC"
   },
   "outputs": [],
   "source": [
    "tweet_column = []\n",
    "for sublist in req_lst:\n",
    "    tweet = ' '.join(sublist)  # Join the words in each sublist to form a single string\n",
    "    tweet_column.append(tweet)\n",
    "\n",
    "print(len(tweet_column))\n",
    "tweet_column[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:31:05.345446Z",
     "iopub.status.busy": "2023-06-22T10:31:05.34433Z",
     "iopub.status.idle": "2023-06-22T10:32:21.078486Z",
     "shell.execute_reply": "2023-06-22T10:32:21.077505Z",
     "shell.execute_reply.started": "2023-06-22T10:31:05.34541Z"
    },
    "id": "cQGvGG5Dh3pC"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Calculate word count vectors for pairs of two documents\n",
    "def calculate_word_count_vectors(documents):\n",
    "\n",
    "    word_count_vectors = []\n",
    "\n",
    "    for i in range(len(tweet_column)):\n",
    "        for j in range(0, len(tweet_column)):\n",
    "            document1 = tweet_column[i]\n",
    "            document2 = tweet_column[j]\n",
    "\n",
    "            # Create a set of unique words from both documents\n",
    "            words = set(document1.split()) | set(document2.split())\n",
    "\n",
    "            # Calculate word count vectors for the selected words\n",
    "            d1 = [Counter(document1.split()).get(feature, 0) for feature in words]\n",
    "            d2 = [Counter(document2.split()).get(feature, 0) for feature in words]\n",
    "\n",
    "            # Format the word count vectors\n",
    "            d1_formatted = \"\".join(str(count) for count in d1)\n",
    "            d2_formatted = \"\".join(str(count) for count in d2)\n",
    "\n",
    "            # Print the word count vectors\n",
    "            #print(f\"d{i+1}, d{j+1} =\", d1_formatted, d2_formatted)\n",
    "            #print()\n",
    "\n",
    "            word_count_vectors.append(f\"d{i+1} = {d1_formatted}\")\n",
    "            word_count_vectors.append(f\"d{j+1} = {d2_formatted}\")\n",
    "\n",
    "    return word_count_vectors\n",
    "\n",
    "document_pairs = calculate_word_count_vectors(tweet_column)\n",
    "print(len(document_pairs))\n",
    "document_pairs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:32:21.080557Z",
     "iopub.status.busy": "2023-06-22T10:32:21.08002Z",
     "iopub.status.idle": "2023-06-22T10:32:21.088038Z",
     "shell.execute_reply": "2023-06-22T10:32:21.086949Z",
     "shell.execute_reply.started": "2023-06-22T10:32:21.080527Z"
    },
    "id": "MpPPfGx8h3pC"
   },
   "outputs": [],
   "source": [
    "#F1(di,dj) function to calculate\n",
    "\n",
    "import math\n",
    "\n",
    "def calculate_similarity_score(d1, d2, sigma, lambd):\n",
    "    num = 0\n",
    "    den = 0\n",
    "\n",
    "    for d1j, d2j in zip(d1, d2):\n",
    "        num += calculate_N_star(d1j, d2j, sigma, lambd)\n",
    "        den += calculate_N_union(d1j, d2j)\n",
    "\n",
    "    if den == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return num / den\n",
    "\n",
    "def calculate_N_star(d1j, d2j, sigma, lambd):\n",
    "    if d1j == 0 and d2j == 0:\n",
    "        return 0\n",
    "\n",
    "    if d1j > 0 and d2j > 0:\n",
    "        return 0.5 * (1 + math.exp(-1 * ((d1j - d2j) / sigma)**2))\n",
    "\n",
    "    return -lambd\n",
    "\n",
    "def calculate_N_union(d1j, d2j):\n",
    "    if d1j == 0 and d2j == 0:\n",
    "        return 0\n",
    "\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:32:21.090096Z",
     "iopub.status.busy": "2023-06-22T10:32:21.08965Z",
     "iopub.status.idle": "2023-06-22T10:32:21.105822Z",
     "shell.execute_reply": "2023-06-22T10:32:21.104662Z",
     "shell.execute_reply.started": "2023-06-22T10:32:21.090059Z"
    },
    "id": "NjUKjFiAh3pC"
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "d1 = [0, 2, 1, 1, 0, 0, 1]\n",
    "d2 = [3, 1, 1, 1, 1, 0, 0]\n",
    "sigma = 2\n",
    "lambd = 1\n",
    "\n",
    "result = calculate_similarity_score(d1, d2, sigma, lambd)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:32:21.107533Z",
     "iopub.status.busy": "2023-06-22T10:32:21.1072Z",
     "iopub.status.idle": "2023-06-22T10:32:21.117531Z",
     "shell.execute_reply": "2023-06-22T10:32:21.116393Z",
     "shell.execute_reply.started": "2023-06-22T10:32:21.107505Z"
    },
    "id": "fgYrOgp4h3pC"
   },
   "outputs": [],
   "source": [
    "#SMTP\n",
    "\n",
    "def calculate_SMTP(d1, d2, sigma, lambd):\n",
    "    f_score = calculate_similarity_score(d1, d2, sigma, lambd)\n",
    "    smtp_score = (f_score + lambd) / (1 + lambd)\n",
    "    return smtp_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:32:21.119984Z",
     "iopub.status.busy": "2023-06-22T10:32:21.119441Z",
     "iopub.status.idle": "2023-06-22T10:32:21.12986Z",
     "shell.execute_reply": "2023-06-22T10:32:21.12887Z",
     "shell.execute_reply.started": "2023-06-22T10:32:21.119943Z"
    },
    "id": "t_3BmSdZh3pD"
   },
   "outputs": [],
   "source": [
    "result = calculate_SMTP(d1, d2, sigma, lambd)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:32:21.131395Z",
     "iopub.status.busy": "2023-06-22T10:32:21.131051Z",
     "iopub.status.idle": "2023-06-22T10:32:21.142957Z",
     "shell.execute_reply": "2023-06-22T10:32:21.141896Z",
     "shell.execute_reply.started": "2023-06-22T10:32:21.131369Z"
    },
    "id": "t8pO1uVyh3pI"
   },
   "outputs": [],
   "source": [
    "len(document_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:32:21.144986Z",
     "iopub.status.busy": "2023-06-22T10:32:21.144537Z",
     "iopub.status.idle": "2023-06-22T10:32:34.731279Z",
     "shell.execute_reply": "2023-06-22T10:32:34.730553Z",
     "shell.execute_reply.started": "2023-06-22T10:32:21.14495Z"
    },
    "id": "wI-Db9EVh3pI"
   },
   "outputs": [],
   "source": [
    "lst1 = []\n",
    "lst2 = []\n",
    "lst = []\n",
    "\n",
    "for i in range(0, len(document_pairs), 2):\n",
    "    dx = document_pairs[i].split(' = ')[1]\n",
    "    dy = document_pairs[i + 1].split(' = ')[1]\n",
    "\n",
    "    dxi = [int(x) for x in dx]\n",
    "    dyi = [int(y) for y in dy]\n",
    "\n",
    "    smtp_score = calculate_SMTP(dxi, dyi, sigma, lambd)\n",
    "    lst.append(smtp_score)\n",
    "    #op = (f\"SMTP score = {smtp_score}\")\n",
    "    #print(op)\n",
    "    #lst1.clear()\n",
    "    #lst2.clear()\n",
    "\n",
    "print(len(lst))\n",
    "lst[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:32:34.733305Z",
     "iopub.status.busy": "2023-06-22T10:32:34.732722Z",
     "iopub.status.idle": "2023-06-22T10:32:34.814352Z",
     "shell.execute_reply": "2023-06-22T10:32:34.81304Z",
     "shell.execute_reply.started": "2023-06-22T10:32:34.733267Z"
    },
    "id": "0IFzVZcih3pI"
   },
   "outputs": [],
   "source": [
    "lst_matrix = np.array(lst).reshape(1000, 1000)\n",
    "lst_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:32:34.81619Z",
     "iopub.status.busy": "2023-06-22T10:32:34.815878Z",
     "iopub.status.idle": "2023-06-22T10:32:36.517339Z",
     "shell.execute_reply": "2023-06-22T10:32:36.516016Z",
     "shell.execute_reply.started": "2023-06-22T10:32:34.816165Z"
    },
    "id": "iVlPu5eMh3pJ"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(lst_matrix, cmap='hot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxzjOxVEh3pJ"
   },
   "source": [
    "SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:32:36.52012Z",
     "iopub.status.busy": "2023-06-22T10:32:36.519034Z",
     "iopub.status.idle": "2023-06-22T10:32:36.527747Z",
     "shell.execute_reply": "2023-06-22T10:32:36.526477Z",
     "shell.execute_reply.started": "2023-06-22T10:32:36.520077Z"
    },
    "id": "oTS6trcNh3pJ"
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "s = df4['label']\n",
    "\n",
    "# Convert the series to a matrix\n",
    "label_matrix = s.values\n",
    "\n",
    "# Reshape the matrix if needed\n",
    "label_matrix = label_matrix.reshape((1000,))\n",
    "\n",
    "unique_val = np.unique(label_matrix)\n",
    "print(unique_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:35:27.928387Z",
     "iopub.status.busy": "2023-06-22T10:35:27.927959Z",
     "iopub.status.idle": "2023-06-22T10:35:28.23146Z",
     "shell.execute_reply": "2023-06-22T10:35:28.230438Z",
     "shell.execute_reply.started": "2023-06-22T10:35:27.928357Z"
    },
    "id": "Gq-XBGANh3pJ"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(lst_matrix, label_matrix, test_size=0.2, random_state=42)\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "svm_acc = clf.score(X_test, y_test)\n",
    "print(\"Accuracy of the model is:\", svm_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oeqZzDwEh3pJ"
   },
   "source": [
    "Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:35:31.405732Z",
     "iopub.status.busy": "2023-06-22T10:35:31.404845Z",
     "iopub.status.idle": "2023-06-22T10:35:31.424089Z",
     "shell.execute_reply": "2023-06-22T10:35:31.422876Z",
     "shell.execute_reply.started": "2023-06-22T10:35:31.405667Z"
    },
    "id": "Ld_h-2W4h3pJ"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "nb_pred = nb_model.predict(X_test)\n",
    "nb_acc = accuracy_score(y_test, nb_pred)\n",
    "print(\"Accuracy of the model is:\", nb_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZgeWFC46h3pJ"
   },
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:35:37.321411Z",
     "iopub.status.busy": "2023-06-22T10:35:37.320337Z",
     "iopub.status.idle": "2023-06-22T10:35:37.359425Z",
     "shell.execute_reply": "2023-06-22T10:35:37.35828Z",
     "shell.execute_reply.started": "2023-06-22T10:35:37.321366Z"
    },
    "id": "2x64GTjLh3pJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train, y_train)\n",
    "\n",
    "log_pred = log_model.predict(X_test)\n",
    "log_acc = accuracy_score(y_test, log_pred)\n",
    "\n",
    "print(\"Accuracy of the model is:\", log_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCSJfJRhh3pK"
   },
   "source": [
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T10:32:36.931357Z",
     "iopub.status.busy": "2023-06-22T10:32:36.9304Z",
     "iopub.status.idle": "2023-06-22T10:32:37.871602Z",
     "shell.execute_reply": "2023-06-22T10:32:37.870391Z",
     "shell.execute_reply.started": "2023-06-22T10:32:36.931294Z"
    },
    "id": "88TlAB0Dh3pK"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n",
    "\n",
    "print(\"Accuracy of the model is:\", rf_acc)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Similarity Measure for Text Processing",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
